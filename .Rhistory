sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)    # изменяем морфологическую форму слов
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # удаление лишних пробелов
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_corpus_clean
# examine the structure of the sms data
str(sms_raw)
# convert spam/ham to factor.
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
# clean up the corpus using tm_map()
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) # remove numbers
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # remove stop words
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation) # remove punctuation
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # eliminate unneeded whitespace
# create a document-term sparse matrix
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_raw
sms_raw$type <- factor(sms_raw$type)
sms_raw
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))   # Приведём все слова в нижний регистр
sms_corpus_clean
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)            # Удаляем числа
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # Удаляем стопслова
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)        # Удаляем пунктуацию
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)    # изменяем морфологическую форму слов
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # удаление лишних пробелов
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
removePunctuation
# функция для исключения пунктуационных символов
replacePunctuation <- function(x) { as.character(gsub("[[:punct:]]+", " ", x)) }
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))   # Приведём все слова в нижний регистр
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)            # Удаляем числа
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # Удаляем стопслова
# функция для исключения пунктуационных символов
replacePunctuation <- function(x) { as.character(gsub("[[:punct:]]+", " ", x)) }
sms_corpus_clean <- tm_map(sms_corpus_clean, replacePunctuation)
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)    # изменяем морфологическую форму слов
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # удаление лишних пробелов
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))   # Приведём все слова в нижний регистр
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)            # Удаляем числа
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # Удаляем стопслова
# функция для исключения пунктуационных символов
replacePunctuation <- function(x) { as.character(gsub("[[:punct:]]+", " ", x)) }
#sms_corpus_clean <- tm_map(sms_corpus_clean, replacePunctuation)        # Удаляем пунктуацию
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)        # Удаляем пунктуацию
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)    # изменяем морфологическую форму слов
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # удаление лишних пробелов
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm
sms_dtm2 <- DocumentTermMatrix(sms_corpus, control = list(
tolower = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE
))
sms_dtm
# creating training and test datasets
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
# also save the labels
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels  <- sms_raw[4170:5559, ]$type
# check that the proportion of spam is similar
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
# word cloud visualization
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
# subset the training data into spam and ham groups
spam <- subset(sms_raw, type == "spam")
ham  <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train, 0.999)
sms_dtm_freq_train
# indicator features for frequent words
findFreqTerms(sms_dtm_train, 5)
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_freq_words
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
sms_freq_words
sms_freq_words %>% glimpse()
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
sms_train
sms_train %>% head()
sms_train %>% as_tibble()
sms_train %>% as_tibble() %>% head()
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
sms_classifier
sms_test_pred <- predict(sms_classifier, sms_test)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
cross_table %>%
as_tibble()
cross_table <- CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual')) %>% as.data.frame()
cross_table %>%
as_tibble()
cross_table %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
cross_table
sms_classifier2 <- naiveBayes(sms_train, sms_train_labels, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
cross_table2 <- CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual')) %>% as.data.frame()
CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
cross_table2 %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
-0.60 * log2(0.60) - 0.40 * log2(0.40)
curve(-x * log2(x) - (1 - x) * log2(1 - x),
col = "red", xlab = "x", ylab = "Entropy", lwd = 4)
library(tidyverse) # инструменты
credit <- read_csv("source/Chapter05/credit.csv")
credit
credit %>% glimpse()
credit %>% count(checking_balance)
credit %>%
count(savings_balance)
summary(credit$months_loan_duration)
credit %>%
select(months_loan_duration) %>%
summary)
credit %>%
select(months_loan_duration) %>%
summary()
summary(credit$amount)
credit %>%
select(months_loan_duration, amount) %>%
summary()
table(credit$default)
credit %>%
count(default)
RNGversion("3.5.2")
train_sample
train_sample <- sample(1000, 900)
train_sample
credit_train <- credit[train_sample, ]
credit_test  <- credit[-train_sample, ]
credit_test
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
library(C50)
credit_train[-17]
credit_train
credit_train["default"]
credit_train[-"default"]
credit_train[!"default"]
colnames(credit_train)
which(colnames(credit_train) == "default")
credit_train[which(colnames(credit_train) == "default")]
credit_train[-which(colnames(credit_train) == "default")]
credit_model <- C5.0(credit_train[-which(colnames(credit_train) == "default")],
credit_train$default)
credit_train$default
credit_model <- C5.0(credit_train[-which(colnames(credit_train) == "default")],
factor(credit_train$default))
read.csv("credit.csv", stringsAsFactors = TRUE)
read.csv("source/Chapter05/credit.csv", stringsAsFactors = TRUE)
str(credit)
credit_model
# display detailed information about the tree
summary(credit_model)
credit_train
credit
credit %>% Мшуц
```
credit %>% View
credit %>%
ggplot(aes(months_loan_duration, amount)) +
geom_col(aes(fill = default))
credit %>%
ggplot(aes(months_loan_duration, amount)) +
geom_point(aes(fill = default))
credit %>%
ggplot(aes(months_loan_duration, amount)) +
geom_point(aes(color = default))
credit %>%
ggplot(aes(months_loan_duration, log(amount))) +
geom_point(aes(color = default)) +
facet_wrap(~)
credit %>%
ggplot(aes(months_loan_duration, log(amount))) +
geom_point(aes(color = default))
credit %>%
ggplot(aes(log(amount), months_loan_duration)) +
geom_point(aes(color = default))
facet_wrap(~default)
credit %>%
ggplot(aes(log(amount), months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~default)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~default)
credit %>%
count(purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = purpose)) +
facet_wrap(~default)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_jitter(aes(color = default)) +
facet_wrap(~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_jitter(aes(color = default)) +
facet_wrap(credit_history~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_jitter(aes(color = default)) +
facet_grid(credit_history~purpose)
credit %>%
count(default)
credit %>%
ggplot(aes(employment_duration, amount)) +
geom_point(aes(color = default))
credit %>%
ggplot(aes(employment_duration, amount)) +
geom_boxplot(aes(color = default))
credit %>%
count(employment_duration)
sum("a")
try(sum("a"))
foo <- try(sum("a"))
foo
?try
{
print('a')
}
if(TRUE)
{
print('a')
foo <- try(sum("a"))
print('b')
}
if(TRUE)
{
print('a')
try(sum("a"))
print('b')
}
if(TRUE)
{
print('a')
sum("a")
print('b')
}
try(sum("a"), silent = TRUE)
{
print('a')
try(sum("a"))
print('b')
}
{
print('a')
sum("a")
print('b')
}
sum("a")
try(sum("a"), silent = TRUE)
{
print('a')
try(sum("a"))
print('b')
}
{
print('a')
sum("a")
print('b')
}
foo <-  try(sum("a"), silent = TRUE)
foo[1]
foo[[1]]
foo[[2]]
foo[2]
foo
class(foo)
class(try(sum("a"), silent = TRUE))
sum(1)
class(try(sum(1), silent = TRUE))
CrossTable(credit_test$default, credit_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# cross tabulation of predicted versus actual classes
library(gmodels)
CrossTable(credit_test$default, credit_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
credit_pred
credit_pred <- predict(credit_model, credit_test)
credit_model
credit_test
credit <- read.csv("source/Chapter05/credit.csv", stringsAsFactors = TRUE)
library(C50)       # деревья решений
library(gmodels)   # оценка эффективности
library(tidyverse) # инструменты
set.seed(123)
train_sample <- sample(1000, 900)
credit_train <- credit[train_sample, ]
credit_test  <- credit[-train_sample, ]
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
credit_model <- C5.0(credit_train[-which(colnames(credit_train) == "default")],
factor(credit_train$default))
credit_model <- C5.0(credit_train[-which(colnames(credit_train) == "default")],
credit_train$default)
credit_pred <- predict(credit_model, credit_test)
CrossTable(credit_test$default, credit_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
cross_table <- CrossTable(credit_test$default, credit_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default')) %>%
as.data.frame()
cross_table %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
credit_boost10 <- C5.0(credit_train[-17], credit_train$default,
trials = 10)
credit_boost_pred10 <- predict(credit_boost10, credit_test)
predict
credit_boost_pred10 <- predict(credit_boost10, credit_test)
credit_boost_pred10
CrossTable(credit_test$default, credit_boost_pred10,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
cross_table2 <- CrossTable(credit_test$default, credit_boost_pred10,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default')) %>%
as.data.frame()
cross_table2 %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
rnorm(1:10)
set.seed(42)
rnorm(1:10)
set.seed(42)
rnorm(1:10)
matrix_dimensions <- list(c("no", "yes"), c("no", "yes"))
matrix_dimensions
names(matrix_dimensions) <- c("predicted", "actual")
matrix_dimensions
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2, dimnames = matrix_dimensions)
error_cost
credit_cost <- C5.0(credit_train[-17], credit_train$default,
costs = error_cost)
credit_cost_pred <- predict(credit_cost, credit_test)
CrossTable(credit_test$default, credit_cost_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
28/35
mushrooms <- read.csv("mushrooms.csv", stringsAsFactors = TRUE)
mushrooms <- read.csv("source/Chapter05/mushrooms.csv", stringsAsFactors = TRUE)
mushrooms
mushrooms %>% glimpse()
mushrooms
mushrooms %>%
as_tibble()
mushrooms %>%
as_tibble() %>% summary()
mushrooms$veil_type <- NULL
table(mushrooms$type)
mushroom_1R <- OneR(type ~ ., data = mushrooms)
## Step 3: Training a model on the data ----
library(OneR)
mushroom_1R <- OneR(type ~ ., data = mushrooms)
mushroom_1R
mushroom_1R_pred <- predict(mushroom_1R, mushrooms)
table(actual = mushrooms$type, predicted = mushroom_1R_pred)
## Step 5: Improving model performance ----
library(RWeka)
mushroom_JRip <- JRip(type ~ ., data = mushrooms)
mushroom_JRip
summary(mushroom_JRip)
mushroom_c5rules <- C5.0(type ~ odor + gill_size, data = mushrooms, rules = TRUE)
summary(mushroom_c5rules)
mushroom_c5rules <- C50::C5.0(type ~ odor + gill_size, data = mushrooms, rules = TRUE)
summary(mushroom_c5rules)
b <- cov(launch$temperature, launch$distress_ct) / var(launch$temperature)
launch <- readюcsv("source/Chapter06/challenger.csv")
launch <- read.csv("source/Chapter06/challenger.csv")
b <- cov(launch$temperature, launch$distress_ct) / var(launch$temperature)
b
a <- mean(launch$distress_ct) - b * mean(launch$temperature)
a
r <- cov(launch$temperature, launch$distress_ct) /
(sd(launch$temperature) * sd(launch$distress_ct))
r
# либо уже готовой функцией:
cor(launch$temperature, launch$distress_ct)
r * (sd(launch$distress_ct) / sd(launch$temperature))
b
r * (sd(launch$distress_ct) / sd(launch$temperature))
b
# confirming the regression line using the lm function (not in text)
model <- lm(distress_ct ~ temperature, data = launch)
model
summary(model)
reg <- function(y, x) {
x <- as.matrix(x)
x <- cbind(Intercept = 1, x)
b <- solve(t(x) %*% x) %*% t(x) %*% y
colnames(b) <- "estimate"
print(b)
}
str(launch)
reg(y = launch$distress_ct, x = launch[2])
reg(y = launch$distress_ct, x = launch[2:4])
launch$distress_ct
launch[2]
launch[2:4]
reg(y = launch$distress_ct, x = launch[2:4])
model <- lm(distress_ct ~ temperature + field_check_pressure + flight_num, data = launch)
model
# use regression model with multiple regression
reg(y = launch$distress_ct, x = launch[2:4])
insurance <- read.csv("source/Chapter06/insurance.csv", stringsAsFactors = TRUE)
str(insurance)
summary(insurance$expenses)
hist(insurance$expenses)
summary(insurance)
cor(insurance[c("age", "bmi", "children", "expenses")])
pairs(insurance[c("age", "bmi", "children", "expenses")])
library(psych)
pairs.panels(insurance[c("age", "bmi", "children", "expenses")])
ins_model <- lm(expenses ~ ., data = insurance) # this is equivalent to above
ins_model
summary(ins_model)
insurance$age2 <- insurance$age^2
insurance$bmi30 <- ifelse(insurance$bmi >= 30, 1, 0)
ins_model2 <- lm(expenses ~ age + age2 + children + bmi + sex +
bmi30*smoker + region, data = insurance)
summary(ins_model2)
cor(insurance$pred, insurance$expenses)
insurance$pred <- predict(ins_model2, insurance)
cor(insurance$pred, insurance$expenses)
abline(a = 0, b = 1, col = "red", lwd = 3, lty = 2)
plot(insurance$pred, insurance$expenses)
abline(a = 0, b = 1, col = "red", lwd = 3, lty = 2)
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 2,
bmi = 30, sex = "male", bmi30 = 1,
smoker = "no", region = "northeast"))
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 2,
bmi = 30, sex = "female", bmi30 = 1,
smoker = "no", region = "northeast"))
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 0,
bmi = 30, sex = "female", bmi30 = 1,
smoker = "no", region = "northeast"))
ins_model2
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 0,
bmi = 30, sex = "female", bmi30 = 1,
smoker = "no", region = "northeast"))
