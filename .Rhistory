reg(y = launch$distress_ct, x = launch[2:4])
insurance <- read.csv("source/Chapter06/insurance.csv", stringsAsFactors = TRUE)
str(insurance)
summary(insurance$expenses)
hist(insurance$expenses)
summary(insurance)
cor(insurance[c("age", "bmi", "children", "expenses")])
pairs(insurance[c("age", "bmi", "children", "expenses")])
library(psych)
pairs.panels(insurance[c("age", "bmi", "children", "expenses")])
ins_model <- lm(expenses ~ ., data = insurance) # this is equivalent to above
ins_model
summary(ins_model)
insurance$age2 <- insurance$age^2
insurance$bmi30 <- ifelse(insurance$bmi >= 30, 1, 0)
ins_model2 <- lm(expenses ~ age + age2 + children + bmi + sex +
bmi30*smoker + region, data = insurance)
summary(ins_model2)
cor(insurance$pred, insurance$expenses)
insurance$pred <- predict(ins_model2, insurance)
cor(insurance$pred, insurance$expenses)
abline(a = 0, b = 1, col = "red", lwd = 3, lty = 2)
plot(insurance$pred, insurance$expenses)
abline(a = 0, b = 1, col = "red", lwd = 3, lty = 2)
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 2,
bmi = 30, sex = "male", bmi30 = 1,
smoker = "no", region = "northeast"))
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 2,
bmi = 30, sex = "female", bmi30 = 1,
smoker = "no", region = "northeast"))
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 0,
bmi = 30, sex = "female", bmi30 = 1,
smoker = "no", region = "northeast"))
ins_model2
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 0,
bmi = 30, sex = "female", bmi30 = 1,
smoker = "no", region = "northeast"))
tee <- c(1, 1, 1, 2, 2, 3, 4, 5, 5, 6, 6, 7, 7, 7, 7)
at1 <- c(1, 1, 1, 2, 2, 3, 4, 5, 5)
at2 <- c(6, 6, 7, 7, 7, 7)
bt1 <- c(1, 1, 1, 2, 2, 3, 4)
bt2 <- c(5, 5, 6, 6, 7, 7, 7, 7)
# compute the SDR
sdr_a <- sd(tee) - (length(at1) / length(tee) * sd(at1) + length(at2) / length(tee) * sd(at2))
sdr_b <- sd(tee) - (length(bt1) / length(tee) * sd(bt1) + length(bt2) / length(tee) * sd(bt2))
# compare the SDR for each split
sdr_a
sdr_b
insurance <- read.csv("source/Chapter06/whitewines.csv")
insurance
insurance %>% glimpse()
library(tidyverse)
insurance %>% glimpse()
hist(wine$quality)
wine <- read.csv("source/Chapter06/whitewines.csv")
wine %>% glimpse()
hist(wine$quality)
wine$quality
wine
wine %>%
ggplot(aes(quality)) +
geom_histogram()
wine %>%
ggplot(aes(quality)) +
#geom_histogram()
geom_boxplot()
wine %>%
count(quality)
# summary statistics of the wine data
summary(wine)
wine_train <- wine[1:3750, ]
wine_test <- wine[3751:4898, ]
## Step 3: Training a model on the data ----
# regression tree using rpart
library(rpart)
m.rpart <- rpart(quality ~ ., data = wine_train)
m.rpart
# get more detailed information about the tree
summary(m.rpart)
rpart.plot(m.rpart, digits = 3)
(rpart.plot)
library(rpart.plot)
rpart.plot(m.rpart, digits = 3)
# a few adjustments to the diagram
rpart.plot(m.rpart, digits = 4, fallen.leaves = TRUE, type = 3, extra = 101)
p.rpart <- predict(m.rpart, wine_test)
p.rpart
# compare the distribution of predicted values vs. actual values
summary(p.rpart)
summary(wine_test$quality)
wine <- read.csv("source/Chapter06/whitewines.csv")
hist(wine$quality)
wine %>%
count(quality)
wine %>%
ggplot(aes(quality)) +
#geom_histogram()
geom_boxplot()
library(tidyverse)
wine %>%
ggplot(aes(quality)) +
#geom_histogram()
geom_boxplot()
wine %>%
count(quality)
wine_train <- wine[1:3750, ]
wine_test <- wine[3751:4898, ]
library(rpart)
m.rpart <- rpart(quality ~ ., data = wine_train)
summary(m.rpart)
library(rpart.plot)
rpart.plot(m.rpart, digits = 3)
p.rpart <- predict(m.rpart, wine_test)
install.packages("Cubist")
library(Cubist)
m.cubist <- cubist(x = wine_train[-12], y = wine_train$quality)
# display basic information about the model tree
m.cubist
# display the tree itself
summary(m.cubist)
# generate predictions for the model
p.cubist <- predict(m.cubist, wine_test)
# summary statistics about the predictions
summary(p.cubist)
# correlation between the predicted and true values
cor(p.cubist, wine_test$quality)
# mean absolute error of predicted and true values
# (uses a custom function defined above)
MAE(wine_test$quality, p.cubist)
library(rpart)
# mean absolute error of predicted and true values
# (uses a custom function defined above)
MAE(wine_test$quality, p.cubist)
# more informative scatterplot matrix
library(psych)
MAE(wine_test$quality, p.cubist)
# use the rpart.plot package to create a visualization
library(rpart.plot)
MAE(wine_test$quality, p.cubist)
# функция средней абсолютной ошибки
MAE <- function(actual, predicted) {
mean(abs(actual - predicted))
}
MAE(wine_test$quality, p.cubist)
wine <- read.csv("source/Chapter07/concrete.csv")
rm(wine)
concrete %>% glimpse()
concrete <- read.csv("source/Chapter07/concrete.csv")
concrete %>% glimpse()
concrete
concrete %>%
pivot_longer(cols = c(-strength),
names_to = "feature",
values_to = "value")
concrete %>%
pivot_longer(cols = everything(),
names_to = "feature",
values_to = "value")
concrete %>%
pivot_longer(cols = everything(),
names_to = "feature",
values_to = "value") %>%
ggplot(aes(value)) +
geom_histogram() +
facet_wrap(~feature)
concrete %>%
pivot_longer(cols = everything(),
names_to = "feature",
values_to = "value") %>%
ggplot(aes(value)) +
geom_histogram() +
facet_wrap(~feature, scales = "free")
# мини-максная нормализация
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalize))
concrete_norm
concrete_norm %>% as_tibble()
?map
map(concrete, normalize)
map(concrete, normalize) %>%
as.data.frame()
map(concrete, normalize) %>% as_tibble()
concrete_norm
map(concrete, normalize) %>% as_tibble()
concrete_norm %>% as_tibble()
concrete_norm %>% summary()
library(tidymodels)
install.packages("tidymodels")
library(tidymodels)
mario_train <- training(mario_split)
mario_train <- training(concrete_norm)
concrete_train <- concrete_norm[1:773, ]
concrete_test <- concrete_norm[774:1030, ]
install.packages("neuralnet")
library(neuralnet)
?neuralnet
concrete_model <- neuralnet(formula = strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train,
hidden = 1)
plot(concrete_model)
set.seed(12345) # to guarantee repeatable results
concrete_model <- neuralnet(formula = strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train,
hidden = 1)
plot(concrete_model)
model_results <- compute(concrete_model, concrete_test[1:8])
predicted_strength <- model_results$net.result
predicted_strength
cor(predicted_strength, concrete_test$strength)
concrete_model2 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train,
hidden = 5)
set.seed(12345) # to guarantee repeatable results
concrete_model2 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train,
hidden = 5)
plot(concrete_model2)
# evaluate the results as we did before
model_results2 <- compute(concrete_model2, concrete_test[1:8])
predicted_strength2 <- model_results2$net.result
cor(predicted_strength2, concrete_test$strength)
softplus <- function(x) { log(1 + exp(x)) }
set.seed(12345) # to guarantee repeatable results
concrete_model3 <- neuralnet(strength ~ cement + slag +
ash + water + superplastic +
coarseagg + fineagg + age,
data = concrete_train, hidden = c(5, 5), act.fct = softplus)
# plot the network
plot(concrete_model3)
# evaluate the results as we did before
model_results3 <- compute(concrete_model3, concrete_test[1:8])
predicted_strength3 <- model_results3$net.result
cor(predicted_strength3, concrete_test$strength)
# note that the predicted and actual values are on different scales
strengths <- data.frame(
actual = concrete$strength[774:1030],
pred = predicted_strength3
)
head(strengths, n = 3)
# this doesn't change the correlations (but would affect absolute error)
cor(strengths$pred, strengths$actual)
# create an unnormalize function to reverse the normalization
unnormalize <- function(x) {
return((x * (max(concrete$strength)) -
min(concrete$strength)) + min(concrete$strength))
}
strengths$pred_new <- unnormalize(strengths$pred)
strengths$error <- strengths$pred_new - strengths$actual
head(strengths, n = 3)
cor(strengths$pred_new, strengths$actual)
letters <- read.csv("source/Chapter07/letterdata.csv", stringsAsFactors = TRUE)
str(letters)
letters
letters_train <- letters[1:16000, ]
letters_test  <- letters[16001:20000, ]
library(kernlab)
letter_classifier <- ksvm(letter ~ ., data = letters_train,
kernel = "vanilladot")
?ksvm
# look at basic information about the model
letter_classifier
letter_predictions <- predict(letter_classifier, letters_test)
table(letter_predictions, letters_test$letter)
agreement <- letter_predictions == letters_test$letter
table(agreement)
prop.table(table(agreement))
set.seed(12345)
letter_classifier_rbf <- ksvm(letter ~ ., data = letters_train, kernel = "rbfdot")
letter_predictions_rbf <- predict(letter_classifier_rbf, letters_test)
agreement_rbf <- letter_predictions_rbf == letters_test$letter
table(agreement_rbf)
prop.table(table(agreement_rbf))
cost_values <- c(1, seq(from = 5, to = 40, by = 5))
accuracy_values <- sapply(cost_values, function(x) {
set.seed(12345)
m <- ksvm(letter ~ ., data = letters_train,
kernel = "rbfdot", C = x)
pred <- predict(m, letters_test)
agree <- ifelse(pred == letters_test$letter, 1, 0)
accuracy <- sum(agree) / nrow(letters_test)
return (accuracy)
})
plot(cost_values, accuracy_values, type = "b")
sessionInfo()
groceries <- read.csv("source/Chapter08/groceries.csv", stringsAsFactors = TRUE)
library(arules)
groceries <- read.transactions("source/Chapter08/groceries.csv")
groceries
summary(groceries)
groceries <- read.transactions("source/Chapter08/groceries.csv", sep = ",")
summary(groceries)
groceries
groceries[1]
groceries[[1]]
groceries[1]
length(groceries)
nrow(groceries)
ncol(groceries)
nrow(groceries) * ncol(groceries)
summary(groceries)[1]
(summary(groceries))[[1]]
(summary(groceries))[1]
summary(groceries)
summary(groceries)$1
foo <- summary(groceries)
foo %>% str()
nrow(groceries) * ncol(groceries)
nrow(groceries) * ncol(groceries) * 0.02609146
inspect(groceries[1:5])
itemFrequency(groceries[, 1:3])
# plot the frequency of items
itemFrequencyPlot(groceries, support = 0.1)
itemFrequencyPlot(groceries, topN = 20)
image(groceries[1:5])
apriori(groceries)
groceryrules <- apriori(groceries, parameter = list(support =
0.006, confidence = 0.25, minlen = 2))
groceryrules
summary(groceryrules)
inspect(groceryrules[1:3])
gc
gc()
as.numeric(system("awk '/MemFree/ {print $2}' /proc/meminfo", intern=TRUE))
berryrules <- subset(groceryrules, items %in% "berries")
inspect(berryrules)
library(tidyverse)
teens <- read.csv("source/Chapter09/sns.csv")
teens <- read.csv("source/Chapter09/snsdata.csv")
teens %>% glimpse()
teens %>%
count(gender)
teens %>%
summary()
teens <- read.csv("snsdata.csv", stringsAsFactors = TRUE)
teens <- read.csv("source/Chapter09/snsdata.csv", stringsAsFactors = TRUE)
teens %>% glimpse()
teens %>%
count(gender)
teens %>%
summary()
?select_if
rowSums(teens$gender)
sum(teens$gender)
sum(teens$age)
teens %>%
mutate(age = ifelse(age >= 13 & age < 20,
age, NA_integer_))
teens
teens <- teens %>%
mutate(age = ifelse(age >= 13 & age < 20,
age, NA_integer_))
teens$age %>% summary()
teens$female <- ifelse(teens$gender == "F" & !is.na(teens$gender), 1, 0)
teens$no_gender <- ifelse(is.na(teens$gender), 1, 0)
teens <- read.csv("source/Chapter09/snsdata.csv", stringsAsFactors = TRUE) %>% as_tibble()
teens
teens$female <- ifelse(teens$gender == "F" & !is.na(teens$gender), 1, 0)
teens$no_gender <- ifelse(is.na(teens$gender), 1, 0)
teens
teens %>%
group_by(gradyear) %>%
summary(age = sum(age, na.rm = TRUE))
teens %>%
group_by(gradyear) %>%
summaries(age = sum(age, na.rm = TRUE))
teens %>%
group_by(gradyear) %>%
summarise(age = sum(age, na.rm = TRUE))
teens %>%
group_by(gradyear) %>%
summarise(age = mean(age, na.rm = TRUE))
teens %>%
group_by(gradyear) %>%
mutate(new_age = mean(age, na.rm = TRUE)) %>% select(new_age)
teens %>%
group_by(gradyear) %>%
mutate(new_age = mean(age, na.rm = TRUE),
age = ifelse(is.na(age), new_age, age))
teens
teens <- teens %>%
group_by(gradyear) %>%
mutate(new_age = mean(age, na.rm = TRUE),
age = ifelse(is.na(age), new_age, age))
teens <- teens %>%
group_by(gradyear) %>%
mutate(new_age = mean(age, na.rm = TRUE),
age = ifelse(is.na(age), new_age, age)) %>%
ungroup() %>%
select(-new_age)
teens
teens[5:40]
teens
interests <- teens[5:40]
interests
?mutate_all
interests %>%
mutate_all(scale)
interests_z <- as.data.frame(lapply(interests, scale))
interests_z
summary(interests$basketball)
summary(interests_z$basketball)
set.seed(2345)
teen_clusters <- kmeans(interests_z, 5)
teen_clusters
teen_clusters$size
set.seed(2345)
teen_clusters <- kmeans(interests_z, 5)
teen_clusters$size
# look at the cluster centers
teen_clusters$centers
teens$cluster <- teen_clusters$cluster
# look at the first five records
teens[1:5, c("cluster", "gender", "age", "friends")]
# mean age by cluster
aggregate(data = teens, age ~ cluster, mean)
# proportion of females by cluster
aggregate(data = teens, female ~ cluster, mean)
# mean number of friends by cluster
aggregate(data = teens, friends ~ cluster, mean)
sms_raw <- read.csv("source/Chapter04/sms_spam.csv", stringsAsFactors = FALSE)
library(tidyverse) # инструменты
library(tm)        # работа с текстами
library(SnowballC) # приведение к морфологической форме
library(wordcloud) # визуализация текстовых обалков
library(e1071)     # алгоритм обучения наивному байесу
library(gmodels)   # оценка эффективности моделей
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))   # Приведём все слова в нижний регистр
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)            # Удаляем числа
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # Удаляем стопслова
# функция для исключения пунктуационных символов
replacePunctuation <- function(x) { as.character(gsub("[[:punct:]]+", " ", x)) }
#sms_corpus_clean <- tm_map(sms_corpus_clean, replacePunctuation)
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)        # Удаляем пунктуацию
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)    # изменяем морфологическую форму слов
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # удаление лишних пробелов
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm2 <- DocumentTermMatrix(sms_corpus, control = list(
tolower = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE
))
# creating training and test datasets
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
# also save the labels
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels  <- sms_raw[4170:5559, ]$type
# check that the proportion of spam is similar
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
sms_freq_words %>% glimpse()
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
sms_test_pred <- predict(sms_classifier, sms_test)
# obtain the predicted probabilities
sms_test_prob <- predict(sms_classifier, sms_test, type = "raw")
predict
?predict
head(sms_test_prob)
sms_test_prob
head(sms_test_prob)
sms_test_labels
# combine the results into a data frame
sms_results <- data.frame(actual_type = sms_test_labels,
predict_type = sms_test_pred,
prob_spam = round(sms_test_prob[ , 2], 5),
prob_ham = round(sms_test_prob[ , 1], 5))
sms_results
sms_results %>% as_tibble()
sms_test_labels
sms_test_pred
sms_results %>% as_tibble()
# the first several test cases
head(sms_results)
head(subset(sms_results, prob_spam > 0.40 & prob_spam < 0.60))
head(subset(sms_results, actual_type != predict_type))
# specifying vectors
table(sms_results$actual_type, sms_results$predict_type)
# test cases where the model was wrong
head(subset(sms_results, actual_type != predict_type))
# specifying vectors
table(sms_results$actual_type, sms_results$predict_type)
sensitivity(sms_results$predict_type, sms_results$actual_type, positive = "spam")
# example using the caret package
library(caret)
sensitivity(sms_results$predict_type, sms_results$actual_type, positive = "spam")
specificity(sms_results$predict_type, sms_results$actual_type, negative = "ham")
