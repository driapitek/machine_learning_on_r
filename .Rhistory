mutate(check = t.x = t.y) %>%
select(check)
cross_table %>%
as_tibble() %>%
mutate(check = t.x = t.y)
cross_table %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
select(check)
cross_table %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq))
cross_table %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum))
cross_table %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
wbcd %>%
select(radius_mean, area_mean, smoothness_mean) %>%
pivot_longer(
cols = everything(),
names_to = "parameter",
values_to = "value"
) %>%
group_by(parameter) %>%
mutate(n_value = normalize(value)) %>%
ungroup() %>%
ggplot(aes(parameter, n_value)) +
geom_boxplot()
wbcd_z <- as.data.frame(scale(wbcd[-1]))
wbcd_train <- wbcd_z[1:469, ]
wbcd_test <- wbcd_z[470:569, ]
# re-classify test cases
wbcd_test_pred <- knn(train = wbcd_train,
test = wbcd_test,
cl = wbcd_train_labels, k = 21)
wbcd_test_pred
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq = FALSE)
cross_table %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
wbcd_test_pred
wbcd_test_labels
wbcd_train
wbcd_test
wbcd_train_labels
cross_table %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
library(tidyverse) # инструменты
sms_spam <- read_csv("source/Chapter04/sms_spam.csv")
sms_spam
sms_spam %>% glimpse()
library(tm)
rm(sms_spam)
sms_raw <- read_csv("source/Chapter04/sms_spam.csv")
sms_raw %>% glimpse()
sms_raw %>%
mutate(type = factor(type))
sms_raw <- sms_raw %>%
mutate(type = factor(type))
VCorpus(VectorSource(sms_raw$text))
VectorSource(sms_raw$text)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
library(tidyverse) # инструменты
library(class)     # метод KNN
library(gmodels)   # Оценка эффективности модели
wbcd <- read_csv("source/Chapter03/wisc_bc_data.csv")
wbcd %>% glimpse()
wbcd <- read_csv("source/Chapter03/wisc_bc_data.csv")
library(tidyverse) # инструменты
library(class)     # метод KNN
library(gmodels)   # Оценка эффективности модели
wbcd <- read_csv("source/Chapter03/wisc_bc_data.csv")
library(tidyverse) # инструменты
library(tm)        # работа с текстами
sms_raw <- read_csv("source/Chapter04/sms_spam.csv")
sms_raw %>% glimpse()
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
print(sms_corpus)
sms_corpus
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2], as.character)
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)            # Удаляем числа
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # Удаляем стопслова
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)        # Удаляем пунктуацию
replacePunctuation <- function(x) { gsub("[[:punct:]]+", " ", x) }
replacePunctuation("hello...world")
removePunctuation("hello...world")
# clean up the corpus using tm_map()
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))   # Приведём все слова в нижний регистр
# функция для исключения пунктуационных символов
replacePunctuation <- function(x) { gsub("[[:punct:]]+", " ", x) }
sms_corpus_clean <- tm_map(sms_corpus_clean, replacePunctuation)        # Удаляем пунктуацию
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))   # Приведём все слова в нижний регистр
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)            # Удаляем числа
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # Удаляем стопслова
sms_corpus_clean <- tm_map(sms_corpus_clean, replacePunctuation)        # Удаляем пунктуацию
# функция для исключения пунктуационных символов
replacePunctuation <- function(x) { gsub("[[:punct:]]+", " ", x) }
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))   # Приведём все слова в нижний регистр
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)            # Удаляем числа
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # Удаляем стопслова
sms_corpus_clean <- tm_map(sms_corpus_clean, replacePunctuation)        # Удаляем пунктуацию
# функция для исключения пунктуационных символов
replacePunctuation <- function(x) { gsub("[[:punct:]]+", " ", x) }
library(SnowballC)
wordStem(c("learn", "learned", "learning", "learns"))
stemDocument
stopwords
?stopwords
stopwords("russian")
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # удаление лишних пробелов
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm
sms_corpus_clean
DocumentTermMatrix(sms_corpus_clean)
sms_raw <- read_csv("source/Chapter04/sms_spam.csv")
sms_raw %>% glimpse()
sms_raw$type <- factor(sms_raw$type)
sms_corpus
lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
lapply(sms_corpus[1:3], as.character)
sms_corpus_clean
sms_corpus
sms_raw <- read_csv("source/Chapter04/sms_spam.csv")
library(tidyverse) # инструменты
library(tm)        # работа с текстами
library(SnowballC) # приведение к морфологической форме
sms_raw <- read_csv("source/Chapter04/sms_spam.csv")
sms_raw %>% glimpse()
sms_raw$type <- factor(sms_raw$type)
# tidy
sms_raw <- sms_raw %>%
mutate(type = factor(type))
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus
sms_raw
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))   # Приведём все слова в нижний регистр
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)            # Удаляем числа
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # Удаляем стопслова
# функция для исключения пунктуационных символов
replacePunctuation <- function(x) { gsub("[[:punct:]]+", " ", x) }
sms_corpus_clean <- tm_map(sms_corpus_clean, replacePunctuation)        # Удаляем пунктуацию
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)    # изменяем морфологическую форму слов
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # удаление лишних пробелов
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_corpus_clean
# examine the structure of the sms data
str(sms_raw)
# convert spam/ham to factor.
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
# clean up the corpus using tm_map()
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) # remove numbers
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # remove stop words
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation) # remove punctuation
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # eliminate unneeded whitespace
# create a document-term sparse matrix
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_raw
sms_raw$type <- factor(sms_raw$type)
sms_raw
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))   # Приведём все слова в нижний регистр
sms_corpus_clean
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)            # Удаляем числа
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # Удаляем стопслова
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)        # Удаляем пунктуацию
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)    # изменяем морфологическую форму слов
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # удаление лишних пробелов
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
removePunctuation
# функция для исключения пунктуационных символов
replacePunctuation <- function(x) { as.character(gsub("[[:punct:]]+", " ", x)) }
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))   # Приведём все слова в нижний регистр
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)            # Удаляем числа
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # Удаляем стопслова
# функция для исключения пунктуационных символов
replacePunctuation <- function(x) { as.character(gsub("[[:punct:]]+", " ", x)) }
sms_corpus_clean <- tm_map(sms_corpus_clean, replacePunctuation)
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)    # изменяем морфологическую форму слов
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # удаление лишних пробелов
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))   # Приведём все слова в нижний регистр
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers)            # Удаляем числа
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # Удаляем стопслова
# функция для исключения пунктуационных символов
replacePunctuation <- function(x) { as.character(gsub("[[:punct:]]+", " ", x)) }
#sms_corpus_clean <- tm_map(sms_corpus_clean, replacePunctuation)        # Удаляем пунктуацию
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation)        # Удаляем пунктуацию
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)    # изменяем морфологическую форму слов
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # удаление лишних пробелов
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm
sms_dtm2 <- DocumentTermMatrix(sms_corpus, control = list(
tolower = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE
))
sms_dtm
# creating training and test datasets
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
# also save the labels
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels  <- sms_raw[4170:5559, ]$type
# check that the proportion of spam is similar
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
# word cloud visualization
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
# subset the training data into spam and ham groups
spam <- subset(sms_raw, type == "spam")
ham  <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train, 0.999)
sms_dtm_freq_train
# indicator features for frequent words
findFreqTerms(sms_dtm_train, 5)
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_freq_words
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
sms_freq_words
sms_freq_words %>% glimpse()
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
sms_train
sms_train %>% head()
sms_train %>% as_tibble()
sms_train %>% as_tibble() %>% head()
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
sms_classifier
sms_test_pred <- predict(sms_classifier, sms_test)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
cross_table %>%
as_tibble()
cross_table <- CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual')) %>% as.data.frame()
cross_table %>%
as_tibble()
cross_table %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
cross_table
sms_classifier2 <- naiveBayes(sms_train, sms_train_labels, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
cross_table2 <- CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual')) %>% as.data.frame()
CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
cross_table2 %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
-0.60 * log2(0.60) - 0.40 * log2(0.40)
curve(-x * log2(x) - (1 - x) * log2(1 - x),
col = "red", xlab = "x", ylab = "Entropy", lwd = 4)
library(tidyverse) # инструменты
credit <- read_csv("source/Chapter05/credit.csv")
credit
credit %>% glimpse()
credit %>% count(checking_balance)
credit %>%
count(savings_balance)
summary(credit$months_loan_duration)
credit %>%
select(months_loan_duration) %>%
summary)
credit %>%
select(months_loan_duration) %>%
summary()
summary(credit$amount)
credit %>%
select(months_loan_duration, amount) %>%
summary()
table(credit$default)
credit %>%
count(default)
RNGversion("3.5.2")
train_sample
train_sample <- sample(1000, 900)
train_sample
credit_train <- credit[train_sample, ]
credit_test  <- credit[-train_sample, ]
credit_test
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
library(C50)
credit_train[-17]
credit_train
credit_train["default"]
credit_train[-"default"]
credit_train[!"default"]
colnames(credit_train)
which(colnames(credit_train) == "default")
credit_train[which(colnames(credit_train) == "default")]
credit_train[-which(colnames(credit_train) == "default")]
credit_model <- C5.0(credit_train[-which(colnames(credit_train) == "default")],
credit_train$default)
credit_train$default
credit_model <- C5.0(credit_train[-which(colnames(credit_train) == "default")],
factor(credit_train$default))
read.csv("credit.csv", stringsAsFactors = TRUE)
read.csv("source/Chapter05/credit.csv", stringsAsFactors = TRUE)
str(credit)
credit_model
# display detailed information about the tree
summary(credit_model)
credit_train
credit
credit %>% Мшуц
```
credit %>% View
credit %>%
ggplot(aes(months_loan_duration, amount)) +
geom_col(aes(fill = default))
credit %>%
ggplot(aes(months_loan_duration, amount)) +
geom_point(aes(fill = default))
credit %>%
ggplot(aes(months_loan_duration, amount)) +
geom_point(aes(color = default))
credit %>%
ggplot(aes(months_loan_duration, log(amount))) +
geom_point(aes(color = default)) +
facet_wrap(~)
credit %>%
ggplot(aes(months_loan_duration, log(amount))) +
geom_point(aes(color = default))
credit %>%
ggplot(aes(log(amount), months_loan_duration)) +
geom_point(aes(color = default))
facet_wrap(~default)
credit %>%
ggplot(aes(log(amount), months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~default)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~default)
credit %>%
count(purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = purpose)) +
facet_wrap(~default)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_jitter(aes(color = default)) +
facet_wrap(~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_jitter(aes(color = default)) +
facet_wrap(credit_history~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_jitter(aes(color = default)) +
facet_grid(credit_history~purpose)
credit %>%
count(default)
credit %>%
ggplot(aes(employment_duration, amount)) +
geom_point(aes(color = default))
credit %>%
ggplot(aes(employment_duration, amount)) +
geom_boxplot(aes(color = default))
credit %>%
count(employment_duration)
sum("a")
try(sum("a"))
foo <- try(sum("a"))
foo
?try
{
print('a')
}
if(TRUE)
{
print('a')
foo <- try(sum("a"))
print('b')
}
if(TRUE)
{
print('a')
try(sum("a"))
print('b')
}
if(TRUE)
{
print('a')
sum("a")
print('b')
}
try(sum("a"), silent = TRUE)
{
print('a')
try(sum("a"))
print('b')
}
{
print('a')
sum("a")
print('b')
}
sum("a")
try(sum("a"), silent = TRUE)
{
print('a')
try(sum("a"))
print('b')
}
{
print('a')
sum("a")
print('b')
}
foo <-  try(sum("a"), silent = TRUE)
foo[1]
foo[[1]]
foo[[2]]
foo[2]
foo
class(foo)
class(try(sum("a"), silent = TRUE))
sum(1)
class(try(sum(1), silent = TRUE))
CrossTable(credit_test$default, credit_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# cross tabulation of predicted versus actual classes
library(gmodels)
CrossTable(credit_test$default, credit_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
credit_pred
credit_pred <- predict(credit_model, credit_test)
credit_model
credit_test
