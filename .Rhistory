sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm
sms_dtm2 <- DocumentTermMatrix(sms_corpus, control = list(
tolower = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE
))
sms_dtm
# creating training and test datasets
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
# also save the labels
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels  <- sms_raw[4170:5559, ]$type
# check that the proportion of spam is similar
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
# word cloud visualization
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
# subset the training data into spam and ham groups
spam <- subset(sms_raw, type == "spam")
ham  <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train, 0.999)
sms_dtm_freq_train
# indicator features for frequent words
findFreqTerms(sms_dtm_train, 5)
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_freq_words
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
sms_freq_words
sms_freq_words %>% glimpse()
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
sms_train
sms_train %>% head()
sms_train %>% as_tibble()
sms_train %>% as_tibble() %>% head()
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
sms_classifier
sms_test_pred <- predict(sms_classifier, sms_test)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
cross_table %>%
as_tibble()
cross_table <- CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual')) %>% as.data.frame()
cross_table %>%
as_tibble()
cross_table %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
cross_table
sms_classifier2 <- naiveBayes(sms_train, sms_train_labels, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
cross_table2 <- CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual')) %>% as.data.frame()
CrossTable(sms_test_pred2, sms_test_labels,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
cross_table2 %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
-0.60 * log2(0.60) - 0.40 * log2(0.40)
curve(-x * log2(x) - (1 - x) * log2(1 - x),
col = "red", xlab = "x", ylab = "Entropy", lwd = 4)
library(tidyverse) # инструменты
credit <- read_csv("source/Chapter05/credit.csv")
credit
credit %>% glimpse()
credit %>% count(checking_balance)
credit %>%
count(savings_balance)
summary(credit$months_loan_duration)
credit %>%
select(months_loan_duration) %>%
summary)
credit %>%
select(months_loan_duration) %>%
summary()
summary(credit$amount)
credit %>%
select(months_loan_duration, amount) %>%
summary()
table(credit$default)
credit %>%
count(default)
RNGversion("3.5.2")
train_sample
train_sample <- sample(1000, 900)
train_sample
credit_train <- credit[train_sample, ]
credit_test  <- credit[-train_sample, ]
credit_test
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
library(C50)
credit_train[-17]
credit_train
credit_train["default"]
credit_train[-"default"]
credit_train[!"default"]
colnames(credit_train)
which(colnames(credit_train) == "default")
credit_train[which(colnames(credit_train) == "default")]
credit_train[-which(colnames(credit_train) == "default")]
credit_model <- C5.0(credit_train[-which(colnames(credit_train) == "default")],
credit_train$default)
credit_train$default
credit_model <- C5.0(credit_train[-which(colnames(credit_train) == "default")],
factor(credit_train$default))
read.csv("credit.csv", stringsAsFactors = TRUE)
read.csv("source/Chapter05/credit.csv", stringsAsFactors = TRUE)
str(credit)
credit_model
# display detailed information about the tree
summary(credit_model)
credit_train
credit
credit %>% Мшуц
```
credit %>% View
credit %>%
ggplot(aes(months_loan_duration, amount)) +
geom_col(aes(fill = default))
credit %>%
ggplot(aes(months_loan_duration, amount)) +
geom_point(aes(fill = default))
credit %>%
ggplot(aes(months_loan_duration, amount)) +
geom_point(aes(color = default))
credit %>%
ggplot(aes(months_loan_duration, log(amount))) +
geom_point(aes(color = default)) +
facet_wrap(~)
credit %>%
ggplot(aes(months_loan_duration, log(amount))) +
geom_point(aes(color = default))
credit %>%
ggplot(aes(log(amount), months_loan_duration)) +
geom_point(aes(color = default))
facet_wrap(~default)
credit %>%
ggplot(aes(log(amount), months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~default)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~default)
credit %>%
count(purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = purpose)) +
facet_wrap(~default)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_point(aes(color = default)) +
facet_wrap(~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_jitter(aes(color = default)) +
facet_wrap(~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_jitter(aes(color = default)) +
facet_wrap(credit_history~purpose)
credit %>%
ggplot(aes(amount, months_loan_duration)) +
geom_jitter(aes(color = default)) +
facet_grid(credit_history~purpose)
credit %>%
count(default)
credit %>%
ggplot(aes(employment_duration, amount)) +
geom_point(aes(color = default))
credit %>%
ggplot(aes(employment_duration, amount)) +
geom_boxplot(aes(color = default))
credit %>%
count(employment_duration)
sum("a")
try(sum("a"))
foo <- try(sum("a"))
foo
?try
{
print('a')
}
if(TRUE)
{
print('a')
foo <- try(sum("a"))
print('b')
}
if(TRUE)
{
print('a')
try(sum("a"))
print('b')
}
if(TRUE)
{
print('a')
sum("a")
print('b')
}
try(sum("a"), silent = TRUE)
{
print('a')
try(sum("a"))
print('b')
}
{
print('a')
sum("a")
print('b')
}
sum("a")
try(sum("a"), silent = TRUE)
{
print('a')
try(sum("a"))
print('b')
}
{
print('a')
sum("a")
print('b')
}
foo <-  try(sum("a"), silent = TRUE)
foo[1]
foo[[1]]
foo[[2]]
foo[2]
foo
class(foo)
class(try(sum("a"), silent = TRUE))
sum(1)
class(try(sum(1), silent = TRUE))
CrossTable(credit_test$default, credit_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
# cross tabulation of predicted versus actual classes
library(gmodels)
CrossTable(credit_test$default, credit_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
credit_pred
credit_pred <- predict(credit_model, credit_test)
credit_model
credit_test
credit <- read.csv("source/Chapter05/credit.csv", stringsAsFactors = TRUE)
library(C50)       # деревья решений
library(gmodels)   # оценка эффективности
library(tidyverse) # инструменты
set.seed(123)
train_sample <- sample(1000, 900)
credit_train <- credit[train_sample, ]
credit_test  <- credit[-train_sample, ]
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
credit_model <- C5.0(credit_train[-which(colnames(credit_train) == "default")],
factor(credit_train$default))
credit_model <- C5.0(credit_train[-which(colnames(credit_train) == "default")],
credit_train$default)
credit_pred <- predict(credit_model, credit_test)
CrossTable(credit_test$default, credit_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
cross_table <- CrossTable(credit_test$default, credit_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default')) %>%
as.data.frame()
cross_table %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
credit_boost10 <- C5.0(credit_train[-17], credit_train$default,
trials = 10)
credit_boost_pred10 <- predict(credit_boost10, credit_test)
predict
credit_boost_pred10 <- predict(credit_boost10, credit_test)
credit_boost_pred10
CrossTable(credit_test$default, credit_boost_pred10,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
cross_table2 <- CrossTable(credit_test$default, credit_boost_pred10,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default')) %>%
as.data.frame()
cross_table2 %>%
as_tibble() %>%
mutate(check = t.x == t.y) %>%
group_by(check) %>%
summarise(check_sum = sum(t.Freq)) %>%
mutate(result = check_sum/sum(check_sum)) %>%
filter(check == TRUE) %>%
pull()
rnorm(1:10)
set.seed(42)
rnorm(1:10)
set.seed(42)
rnorm(1:10)
matrix_dimensions <- list(c("no", "yes"), c("no", "yes"))
matrix_dimensions
names(matrix_dimensions) <- c("predicted", "actual")
matrix_dimensions
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2, dimnames = matrix_dimensions)
error_cost
credit_cost <- C5.0(credit_train[-17], credit_train$default,
costs = error_cost)
credit_cost_pred <- predict(credit_cost, credit_test)
CrossTable(credit_test$default, credit_cost_pred,
prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
dnn = c('actual default', 'predicted default'))
28/35
mushrooms <- read.csv("mushrooms.csv", stringsAsFactors = TRUE)
mushrooms <- read.csv("source/Chapter05/mushrooms.csv", stringsAsFactors = TRUE)
mushrooms
mushrooms %>% glimpse()
mushrooms
mushrooms %>%
as_tibble()
mushrooms %>%
as_tibble() %>% summary()
mushrooms$veil_type <- NULL
table(mushrooms$type)
mushroom_1R <- OneR(type ~ ., data = mushrooms)
## Step 3: Training a model on the data ----
library(OneR)
mushroom_1R <- OneR(type ~ ., data = mushrooms)
mushroom_1R
mushroom_1R_pred <- predict(mushroom_1R, mushrooms)
table(actual = mushrooms$type, predicted = mushroom_1R_pred)
## Step 5: Improving model performance ----
library(RWeka)
mushroom_JRip <- JRip(type ~ ., data = mushrooms)
mushroom_JRip
summary(mushroom_JRip)
mushroom_c5rules <- C5.0(type ~ odor + gill_size, data = mushrooms, rules = TRUE)
summary(mushroom_c5rules)
mushroom_c5rules <- C50::C5.0(type ~ odor + gill_size, data = mushrooms, rules = TRUE)
summary(mushroom_c5rules)
b <- cov(launch$temperature, launch$distress_ct) / var(launch$temperature)
launch <- readюcsv("source/Chapter06/challenger.csv")
launch <- read.csv("source/Chapter06/challenger.csv")
b <- cov(launch$temperature, launch$distress_ct) / var(launch$temperature)
b
a <- mean(launch$distress_ct) - b * mean(launch$temperature)
a
r <- cov(launch$temperature, launch$distress_ct) /
(sd(launch$temperature) * sd(launch$distress_ct))
r
# либо уже готовой функцией:
cor(launch$temperature, launch$distress_ct)
r * (sd(launch$distress_ct) / sd(launch$temperature))
b
r * (sd(launch$distress_ct) / sd(launch$temperature))
b
# confirming the regression line using the lm function (not in text)
model <- lm(distress_ct ~ temperature, data = launch)
model
summary(model)
reg <- function(y, x) {
x <- as.matrix(x)
x <- cbind(Intercept = 1, x)
b <- solve(t(x) %*% x) %*% t(x) %*% y
colnames(b) <- "estimate"
print(b)
}
str(launch)
reg(y = launch$distress_ct, x = launch[2])
reg(y = launch$distress_ct, x = launch[2:4])
launch$distress_ct
launch[2]
launch[2:4]
reg(y = launch$distress_ct, x = launch[2:4])
model <- lm(distress_ct ~ temperature + field_check_pressure + flight_num, data = launch)
model
# use regression model with multiple regression
reg(y = launch$distress_ct, x = launch[2:4])
insurance <- read.csv("source/Chapter06/insurance.csv", stringsAsFactors = TRUE)
str(insurance)
summary(insurance$expenses)
hist(insurance$expenses)
summary(insurance)
cor(insurance[c("age", "bmi", "children", "expenses")])
pairs(insurance[c("age", "bmi", "children", "expenses")])
library(psych)
pairs.panels(insurance[c("age", "bmi", "children", "expenses")])
ins_model <- lm(expenses ~ ., data = insurance) # this is equivalent to above
ins_model
summary(ins_model)
insurance$age2 <- insurance$age^2
insurance$bmi30 <- ifelse(insurance$bmi >= 30, 1, 0)
ins_model2 <- lm(expenses ~ age + age2 + children + bmi + sex +
bmi30*smoker + region, data = insurance)
summary(ins_model2)
cor(insurance$pred, insurance$expenses)
insurance$pred <- predict(ins_model2, insurance)
cor(insurance$pred, insurance$expenses)
abline(a = 0, b = 1, col = "red", lwd = 3, lty = 2)
plot(insurance$pred, insurance$expenses)
abline(a = 0, b = 1, col = "red", lwd = 3, lty = 2)
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 2,
bmi = 30, sex = "male", bmi30 = 1,
smoker = "no", region = "northeast"))
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 2,
bmi = 30, sex = "female", bmi30 = 1,
smoker = "no", region = "northeast"))
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 0,
bmi = 30, sex = "female", bmi30 = 1,
smoker = "no", region = "northeast"))
ins_model2
predict(ins_model2,
data.frame(age = 30, age2 = 30^2, children = 0,
bmi = 30, sex = "female", bmi30 = 1,
smoker = "no", region = "northeast"))
tee <- c(1, 1, 1, 2, 2, 3, 4, 5, 5, 6, 6, 7, 7, 7, 7)
at1 <- c(1, 1, 1, 2, 2, 3, 4, 5, 5)
at2 <- c(6, 6, 7, 7, 7, 7)
bt1 <- c(1, 1, 1, 2, 2, 3, 4)
bt2 <- c(5, 5, 6, 6, 7, 7, 7, 7)
# compute the SDR
sdr_a <- sd(tee) - (length(at1) / length(tee) * sd(at1) + length(at2) / length(tee) * sd(at2))
sdr_b <- sd(tee) - (length(bt1) / length(tee) * sd(bt1) + length(bt2) / length(tee) * sd(bt2))
# compare the SDR for each split
sdr_a
sdr_b
insurance <- read.csv("source/Chapter06/whitewines.csv")
insurance
insurance %>% glimpse()
library(tidyverse)
insurance %>% glimpse()
hist(wine$quality)
wine <- read.csv("source/Chapter06/whitewines.csv")
wine %>% glimpse()
hist(wine$quality)
wine$quality
wine
wine %>%
ggplot(aes(quality)) +
geom_histogram()
wine %>%
ggplot(aes(quality)) +
#geom_histogram()
geom_boxplot()
wine %>%
count(quality)
# summary statistics of the wine data
summary(wine)
wine_train <- wine[1:3750, ]
wine_test <- wine[3751:4898, ]
## Step 3: Training a model on the data ----
# regression tree using rpart
library(rpart)
m.rpart <- rpart(quality ~ ., data = wine_train)
m.rpart
# get more detailed information about the tree
summary(m.rpart)
rpart.plot(m.rpart, digits = 3)
(rpart.plot)
library(rpart.plot)
rpart.plot(m.rpart, digits = 3)
# a few adjustments to the diagram
rpart.plot(m.rpart, digits = 4, fallen.leaves = TRUE, type = 3, extra = 101)
p.rpart <- predict(m.rpart, wine_test)
p.rpart
# compare the distribution of predicted values vs. actual values
summary(p.rpart)
summary(wine_test$quality)
