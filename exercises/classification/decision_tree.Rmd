# Глава 5: Часть 1. Classification using Decision Trees

Классификация с использованием деревьев принятия решений.

Алгоритм C5.0

## Чтобы лучше понимать Деревья

Степень, в которой подмножество примеров содержит только один класс, называется `чистотой`.

Подмножество, которое состоит только из одного класса, называется `чистым`.

В алгоритме С5.0 для определения показателя чистоты используется ЭНТРОПИЯ.

Предположим что у нас есть раздел данных с двумя классами: 60% красный и 40% белый.

Тогда показатель энтропии для этого случая выглядит так:

```{r}
-0.60 * log2(0.60) - 0.40 * log2(0.40)
```

Энтропичя в этой формуле достигает пикового значения при x = 0.5. Оно и понятно.

```{r}
curve(-x * log2(x) - (1 - x) * log2(1 - x),
      col = "red", xlab = "x", ylab = "Entropy", lwd = 4)
```

INFOGAIN или ПРИРОСТ ИНФОРМАЦИИ --- это изменение однородности, то есть РАЗНОСТЬ двух энтропий, которое может возникнуть при разделении по всем возможным признакам.

Чтобы полученный показатель был устойчивее к классам с небольшим набором данных, его взвешивают на кол-во данных в классе.

В итоге, чем больше полученный прирост информации, в результате разделения,тем лучше данный признак подходит для разделения.

Чтобы дерево не разрасталось, есть два подхода:

  * ранняя остановка --- его можно остановить либо по числу точек в группе, либо по числу разделяющих признаков. Недостаток такого подхода в том, что нет гарантий что скрытые или неявные паттерны будут выявлены. 
  * поздняя остановка --- мы намеренно даём алгоритму разрастись, а потом с конца удаляем не нужные разделения.

## 1. Сбор данных

```{r}
library(tidyverse) # инструменты
library(C50)       # деревья решений
library(gmodels)   # оценка эффективности
```

```{r}
#credit <- read_csv("source/Chapter05/credit.csv")
credit <- read.csv("source/Chapter05/credit.csv", stringsAsFactors = TRUE)
```


Данные --- кредитный скоринг.

Что хотим --- выявить факторы, которые связаны с более высоким риском невозврата кредита.

## 2. Исследование и подготовка данных


```{r}
credit %>% glimpse()
```


DM --- это немецкие марки


Посмотрим какие градации текущего и накопительного баланса есть у заёмщиков? Они здесь сразу разбинены.

```{r}
credit %>% 
  count(checking_balance)

credit %>% 
  count(savings_balance)
```

Продолжительность кредита и запрашиваемая сумма числовые переменные:

```{r}
credit %>% 
  select(months_loan_duration, amount) %>% 
  summary()
```

Ну и самая главная переменная `default` --- обанкротился ли заёмщик или нет. Соответственно `no` --- означает что кредит вернули, `yes` --- что заёмщик обанкротился и не вернул кредит.

```{r}
credit %>% 
  count(default)
```


```{r}
credit %>% 
  ggplot(aes(amount, months_loan_duration)) + 
  geom_jitter(aes(color = default)) +
  facet_grid(credit_history~purpose)
```


```{r}
credit %>% 
  ggplot(aes(employment_duration, amount)) +
  geom_boxplot(aes(color = default))
```


### 2.1. Сабсеттинг тестового и тренировочного набора

Этим скриптом мы вытащим из генеральной совокупности рандомные выборки

```{r}
set.seed(123)
train_sample <- sample(1000, 900)

credit_train <- credit[train_sample, ]
credit_test  <- credit[-train_sample, ]
```

```{r}
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
```

В тестовой и тренировчной выборках примерно одинаковое кол-во уровней предиканта, поэтому можем приступать к обучению модели.

## 3. Обучение модели

```{r}
credit_model <- C5.0(credit_train[-which(colnames(credit_train) == "default")],
                     credit_train$default)
```

Посмотрим детали полученной модели

```{r}
credit_model

summary(credit_model)
```

первые три строки этой выдачи можно интерпретировать так:

  * Если остаток на текущем счёте неизвестен или превышет 200 DM,  кредит классифицируется как «маловероятно, что он будет не возвращён»
  * В противном случае, если остаток на текущем счете отрицательный или меньше 200 марок...
    * ... и у заявителя отличная или очень хорошая кредитная история, то кредит классифицируется как «с высокой вероятностью невозвращения».

Иногда дерево решения приводит к решениям, которые являются бессмысленными с точки зрения логики. Например почему заявитель у которого хорошая кредитная история, не вернёт кредит?
Иногда алгоритм создает такие протеворечивые правила. Это может быть как аномалией, так и скрытой закономерностью данных. В любом случае, каждый такой случай нужно подробно изучать, чтобы понять имеет ли логика дерева смысл для использования в бизнесе.


## 4. Оценка эффективности

Применим созданную модельку, к тестовым данным

```{r}
credit_pred <- predict(credit_model, credit_test)
```


```{r}
CrossTable(credit_test$default, credit_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```

Итак, наша модель правильно определила, что из 100 заявлений на получение кредита, входящий в тестовый набор данных, 55 не закончились банкротством, а в 15 случаях крдеит не был возвращён.

Это означает, что

```{r}
cross_table <- CrossTable(credit_test$default, credit_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default')) %>% 
  as.data.frame()

cross_table %>% 
  as_tibble() %>% 
  mutate(check = t.x == t.y) %>% 
  group_by(check) %>% 
  summarise(check_sum = sum(t.Freq)) %>% 
  mutate(result = check_sum/sum(check_sum)) %>% 
  filter(check == TRUE) %>% 
  pull()
```

70% прогнозов были сделаны точно, но на самом деле это не очень хороший результат.


## 5. Повышение эффективности модели

Как мы увидели выше, эффективность модели оставляет желать лучшего. Но хорошая новость в том, что её можно улучшить.

Можно смэтчить несколько слабых моделей и получится трансформер, лучший чем каждая из них по отдельности. Это называется усилением модели.

```{r}
credit_boost10 <- C5.0(credit_train[-17], credit_train$default,
                       trials = 10)
```

Параметр trials указывает на то, сколько деревьев будем добавлять.

Посмотрим что получилось

```{r}
credit_boost_pred10 <- predict(credit_boost10, credit_test)
```

```{r}
CrossTable(credit_test$default, credit_boost_pred10,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```



```{r}
cross_table2 <- CrossTable(credit_test$default, credit_boost_pred10,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default')) %>% 
  as.data.frame()

cross_table2 %>% 
  as_tibble() %>% 
  mutate(check = t.x == t.y) %>% 
  group_by(check) %>% 
  summarise(check_sum = sum(t.Freq)) %>% 
  mutate(result = check_sum/sum(check_sum)) %>% 
  filter(check == TRUE) %>% 
  pull()
```

результат не особо улучшился. Нужно пробовать ещё.

Тут стоит обратить внимание, что ложноотрицательные ошибки и ложноположительные имеют разную «стоимость».

Плательщик который не отдаст деньги, может быть гораздо дороже потенциально невыданного кредита.

У алгоритма C5.0, можно указать какие ошибки дороже, и соответственно взвесить их.

Для построения матрицы штрафов нужно определить её размеры. Поскольку и прогнозируемые и фактические классы могут иметь только два значения «yes» и «no», то мы создаём матрицу 2x2.

В общем случае матрица должна состоять из количества значений классов. Так же, чтобы не путаться, мы дадим матрице 

```{r}
matrix_dimensions <- list(c("no", "yes"), c("no", "yes"))

names(matrix_dimensions) <- c("predicted", "actual")
matrix_dimensions
```

Теперь нужно указать штрафы. R заполняет сверху вниз по столбцам и слева направо. Зная это, добавим соответствующие коэффициенты.

Предположим, что невозвращённый кредит обходится банку дороже в 4 раза, чем не выданный.

```{r}
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2, dimnames = matrix_dimensions)
error_cost
```

СОгласно этой матрице, получаем что если алгоритм правильно классифицирует, то мы не штрафуем резултаты. Если результат ложноположительный --- штраф 1. Ложноотрицательный --- штраф 4.


```{r}
credit_cost <- C5.0(credit_train[-17], credit_train$default,
                          costs = error_cost)
credit_cost_pred <- predict(credit_cost, credit_test)

CrossTable(credit_test$default, credit_cost_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```

Этот результат уже получше. Фактически 80% невозвращённых кредитов были спрогнозированы правильно.

```{r}
28/35
```





